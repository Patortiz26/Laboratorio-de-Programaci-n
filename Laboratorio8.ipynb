{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": true,
      "title_cell": "Tabla de Contenidos",
      "title_sidebar": "Contenidos",
      "toc_cell": false,
      "toc_position": {
        "height": "calc(100% - 180px)",
        "left": "10px",
        "top": "150px",
        "width": "241.867px"
      },
      "toc_section_display": true,
      "toc_window_display": true
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "colab": {
      "name": "Laboratorio8.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "LCOUC4jss148",
        "GtG74Cphq56p"
      ],
      "include_colab_link": true
    },
    "deepnote_notebook_id": "038fcdf2-d87a-4a74-89c6-f5afff22afb6",
    "deepnote": {},
    "deepnote_execution_queue": []
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Patortiz26/Laboratorio-de-Programaci-n/blob/main/Laboratorio8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XUZ1dFPHzAHl",
        "cell_id": "00000-7111e3ae-b60e-4569-b774-a13ef1b95f77",
        "deepnote_cell_type": "markdown"
      },
      "source": [
        "<h1><center>Laboratorio 8: ¿Superhéroe o Villano? 🦸</center></h1>\n",
        "\n",
        "<center><strong>MDS7202: Laboratorio de Programación Científica para Ciencia de Datos</strong></center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UD8X1uhGzAHq",
        "cell_id": "00001-988ebcea-7685-4ad4-968d-5530ff0099a7",
        "deepnote_cell_type": "markdown"
      },
      "source": [
        "### Cuerpo Docente:\n",
        "\n",
        "- Profesor: Pablo Badilla\n",
        "- Auxiliar: Ignacio Meza D.\n",
        "- Ayudante: Constanza Peña"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tXflExjqzAHr",
        "cell_id": "00002-038ebafa-6641-4c2a-b2e8-62ad2018b88e",
        "deepnote_cell_type": "markdown"
      },
      "source": [
        "### Equipo:\n",
        "\n",
        "- Patricio Ortiz\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AD-V0bbZzAHr",
        "cell_id": "00003-913d0cc4-e146-4ff9-a0e3-26a20c808d7c",
        "deepnote_cell_type": "markdown"
      },
      "source": [
        "### **Link de repositorio de GitHub:** `https://github.com/Patortiz26/Laboratorio-de-Programaci-n/`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EcnsiQMkzAHr",
        "cell_id": "00004-e5841000-37dc-494f-a9b8-3c30765c243a",
        "deepnote_cell_type": "markdown"
      },
      "source": [
        "### Indice \n",
        "\n",
        "1. [Temas a tratar](#Temas-a-tratar:)\n",
        "3. [Descripcción del laboratorio](#Descripción-del-laboratorio.)\n",
        "4. [Desarrollo](#Desarrollo)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6uBLPj1PzAHs",
        "cell_id": "00005-64f7c2d0-4287-4f3a-9b4b-2c5b829f606c",
        "deepnote_cell_type": "markdown"
      },
      "source": [
        "# Temas a tratar\n",
        "\n",
        "- Exploración del dataset y los resultados a través de visualizaciones interactivas usando `plotly`.\n",
        "- Introducción a procesamiento del lenguaje natural.\n",
        "- Clasificación en `scikit-learn`\n",
        "- Uso de pipelines.\n",
        "\n",
        "## Reglas:\n",
        "\n",
        "- Fecha de entrega: 26/11/2021\n",
        "- **Grupos de 2 personas**\n",
        "- **Ausentes** deberán realizar la actividad solos. \n",
        "- Cualquier duda fuera del horario de clases al foro. Mensajes al equipo docente serán respondidos por este medio.\n",
        "- Prohibidas las copias. \n",
        "- Pueden usar cualquer matrial del curso que estimen conveniente.\n",
        "\n",
        "### Objetivos principales del laboratorio\n",
        "\n",
        "- Aplicar las ventajas que nos ofrece crear un pipeline.\n",
        "- Obtener caracteristicas desde texto.\n",
        "- Visualizar el funcionamiento de clasificadores.\n",
        "- Realizar una GridSearch sobre un conjunto de clasificadores.\n",
        "\n",
        "El laboratorio deberá ser desarrollado sin el uso indiscriminado de iteradores nativos de python (aka \"for\", \"while\"). La idea es que aprendan a exprimir al máximo las funciones optimizadas que nos entrega `pandas`, las cuales vale mencionar, son bastante más eficientes que los iteradores nativos sobre DataFrames."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MhISwri4zAHy",
        "cell_id": "00006-b8353b3b-8f85-4aa6-9379-96902d3d0bf3",
        "deepnote_cell_type": "markdown"
      },
      "source": [
        "#Importamos librerias utiles 😸"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-03-29T00:08:16.884674Z",
          "start_time": "2021-03-29T00:08:16.349846Z"
        },
        "id": "uyc33dKdzAHy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "deepnote_output_heights": [
          null,
          21.199996948242188
        ],
        "deepnote_to_be_reexecuted": false,
        "source_hash": "7ce9748b",
        "execution_start": 1637348694866,
        "execution_millis": 36497,
        "cell_id": "00007-e696189c-3187-4899-bf04-8034b0e8a595",
        "deepnote_cell_type": "code",
        "outputId": "9e8c23c5-0c73-4766-ecea-c7b56f17a6b4"
      },
      "source": [
        "# Librería Core del lab.\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "from sklearn.model_selection import train_test_split \n",
        "\n",
        "# Pre-procesamiento\n",
        "from sklearn.feature_selection import SelectPercentile, f_classif\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# Clasifación\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.experimental import enable_halving_search_cv  # noqa\n",
        "from sklearn.model_selection import HalvingGridSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Metricas de evaluación\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import cohen_kappa_score\n",
        "\n",
        "# Librería para plotear\n",
        "!pip install --upgrade plotly\n",
        "import plotly.express as px\n",
        "from plotly.subplots import make_subplots\n",
        "import plotly.graph_objects as go\n",
        "\n",
        "# Proyecciones en baja dimensionalidad: UMAP\n",
        "!pip install umap-learn\n",
        "\n",
        "# Librería para NLP\n",
        "!pip install nltk\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk import word_tokenize  \n",
        "from nltk.stem import PorterStemmer\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: plotly in /usr/local/lib/python3.7/dist-packages (5.4.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from plotly) (1.15.0)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.7/dist-packages (from plotly) (8.0.1)\n",
            "Requirement already satisfied: umap-learn in /usr/local/lib/python3.7/dist-packages (0.5.2)\n",
            "Requirement already satisfied: pynndescent>=0.5 in /usr/local/lib/python3.7/dist-packages (from umap-learn) (0.5.5)\n",
            "Requirement already satisfied: numba>=0.49 in /usr/local/lib/python3.7/dist-packages (from umap-learn) (0.51.2)\n",
            "Requirement already satisfied: scipy>=1.0 in /usr/local/lib/python3.7/dist-packages (from umap-learn) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from umap-learn) (1.19.5)\n",
            "Requirement already satisfied: scikit-learn>=0.22 in /usr/local/lib/python3.7/dist-packages (from umap-learn) (1.0.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from umap-learn) (4.62.3)\n",
            "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba>=0.49->umap-learn) (0.34.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba>=0.49->umap-learn) (57.4.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from pynndescent>=0.5->umap-learn) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.22->umap-learn) (3.0.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk) (1.15.0)\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xpOTbQcxbSiy",
        "cell_id": "00008-9c535dd9-01e0-4804-a325-7b5d36a20a32",
        "deepnote_cell_type": "markdown"
      },
      "source": [
        "# 1. ¿Quien es Bat Cow?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Q93vbNS25bM",
        "cell_id": "00009-43ac5618-611f-4712-aec7-faaa53d72d08",
        "deepnote_cell_type": "markdown"
      },
      "source": [
        "<p align=\"center\">\n",
        "  <img src=\"https://i.imgur.com/D9f1RHy.jpg\" width=\"350\">\n",
        "</p>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jnmZfFpxTTYX",
        "cell_id": "00010-632e9494-ce9c-4d54-8e57-e700baed4302",
        "deepnote_cell_type": "markdown"
      },
      "source": [
        "En vez de estar desarrollando las evaluaciones correspondientes a su curso, su profesor de catedra y su auxiliar discuten acerca la alineación (héroe o villano) del personaje de ficción Bat-Cow. \n",
        "\n",
        "El cuerpo docente, no logra ponerse de acuerdo si el personaje es bueno, neutral o malo: el auxiliar plantea que Bat-cow posee una siniestra mirada, intrigante pero común característica de los personajes malvados. \n",
        "Por otra parte, extendiendo las ideas de Rousseau, el profesor plantea que tal como los humanos no nacen malos, no existe motivo por el cual una vaca con superpoderes deba serlo.\n",
        "\n",
        "Sin embargo, ambos concuerdan que es difícil estimar la alineación solo usando los atributos físicos, por lo que creen el análisis debe ser complementado aún más antes de comunicarle los resultados a su estudiantado. Buscando más información, ambos sujetos se percatan de la existencia de un excelente antecedente para estimar la alineación: la historia personal de cada superhéroe o villano.\n",
        "\n",
        "Es por esto le solicitan que construya y optimice un clasificador basado en texto el cual analice la alineación de cada personaje basado en su historia personal.\n",
        "\n",
        "Para este laboratorio deben trabajar con los datos `df_comics.csv` y `comics_no_label.csv` subidos a u-cursos. El primero es un conjunto de datos que les servirá para entrenar un modelo de clasificación, mientras que el segundo es un dataset con personajes de ficción no etiquetados a predecir (sí, aquí está la misteriosa Batcow).\n",
        "\n",
        "Para comenzar cargue los dataset señalados y visualice a través de un head los atributos que poseen cada uno de los dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jqq-s010Iwl1",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "c60dc4a7",
        "execution_start": 1637348657022,
        "execution_millis": 27,
        "cell_id": "00011-9a36781e-c26a-46de-b4bf-a5448a347cab",
        "deepnote_cell_type": "code",
        "outputId": "7fb06c64-a1fd-4e74-89d3-3dacfb868620"
      },
      "source": [
        "# Si usted está utilizando Colabolatory le puede ser útil este código para cargar los archivos.\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    drive.mount(\"/content/drive\")\n",
        "    path = '/content/drive/My Drive/Colab Notebooks/MDS7202 - Laboratorio de programación/Lab 8/'\n",
        "except: \n",
        "    print('Ignorando conexión drive-colab')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bED3w3tDbSCf",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "443d6e8",
        "execution_start": 1637348732856,
        "execution_millis": 325,
        "cell_id": "00012-8b0c36c2-aeaa-4ba1-9611-45f0599aa584",
        "deepnote_cell_type": "code"
      },
      "source": [
        "df_comics = pd.read_csv(path+'df_comics.csv')\n",
        "df_comics_no_label = pd.read_csv(path+'comics_no_label.csv')\n",
        "df_comics = df_comics.dropna(subset=['history_text']) # eliminar ejemplos sin historia"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00013-2cd3a433-4f43-4a9e-92f5-caf54a662db2",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "b986316d",
        "execution_start": 1637348731943,
        "execution_millis": 654,
        "deepnote_cell_type": "code",
        "id": "anMLI82m08lg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 620
        },
        "outputId": "5c649e5f-a255-4396-dd47-9e9816553d53"
      },
      "source": [
        "# queda a labor de su equipo hacer el análisis exploratorio\n",
        "df_comics.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>name</th>\n",
              "      <th>real_name</th>\n",
              "      <th>full_name</th>\n",
              "      <th>overall_score</th>\n",
              "      <th>history_text</th>\n",
              "      <th>powers_text</th>\n",
              "      <th>intelligence_score</th>\n",
              "      <th>strength_score</th>\n",
              "      <th>speed_score</th>\n",
              "      <th>durability_score</th>\n",
              "      <th>power_score</th>\n",
              "      <th>combat_score</th>\n",
              "      <th>superpowers</th>\n",
              "      <th>alter_egos</th>\n",
              "      <th>aliases</th>\n",
              "      <th>place_of_birth</th>\n",
              "      <th>first_appearance</th>\n",
              "      <th>creator</th>\n",
              "      <th>alignment</th>\n",
              "      <th>occupation</th>\n",
              "      <th>base</th>\n",
              "      <th>teams</th>\n",
              "      <th>relatives</th>\n",
              "      <th>gender</th>\n",
              "      <th>type_race</th>\n",
              "      <th>height</th>\n",
              "      <th>weight</th>\n",
              "      <th>eye_color</th>\n",
              "      <th>hair_color</th>\n",
              "      <th>skin_color</th>\n",
              "      <th>img</th>\n",
              "      <th>has_electrokinesis</th>\n",
              "      <th>has_energy_constructs</th>\n",
              "      <th>has_mind_control_resistance</th>\n",
              "      <th>has_matter_manipulation</th>\n",
              "      <th>has_telepathy_resistance</th>\n",
              "      <th>has_mind_control</th>\n",
              "      <th>has_enhanced_hearing</th>\n",
              "      <th>has_dimensional_travel</th>\n",
              "      <th>...</th>\n",
              "      <th>has_fire_resistance</th>\n",
              "      <th>has_fire_control</th>\n",
              "      <th>has_dexterity</th>\n",
              "      <th>has_reality_warping</th>\n",
              "      <th>has_illusions</th>\n",
              "      <th>has_energy_beams</th>\n",
              "      <th>has_peak_human_condition</th>\n",
              "      <th>has_shapeshifting</th>\n",
              "      <th>has_heat_resistance</th>\n",
              "      <th>has_jump</th>\n",
              "      <th>has_self-sustenance</th>\n",
              "      <th>has_energy_absorption</th>\n",
              "      <th>has_cold_resistance</th>\n",
              "      <th>has_magic</th>\n",
              "      <th>has_telekinesis</th>\n",
              "      <th>has_toxin_and_disease_resistance</th>\n",
              "      <th>has_telepathy</th>\n",
              "      <th>has_regeneration</th>\n",
              "      <th>has_immortality</th>\n",
              "      <th>has_teleportation</th>\n",
              "      <th>has_force_fields</th>\n",
              "      <th>has_energy_manipulation</th>\n",
              "      <th>has_endurance</th>\n",
              "      <th>has_longevity</th>\n",
              "      <th>has_weapon-based_powers</th>\n",
              "      <th>has_energy_blasts</th>\n",
              "      <th>has_enhanced_senses</th>\n",
              "      <th>has_invulnerability</th>\n",
              "      <th>has_stealth</th>\n",
              "      <th>has_marksmanship</th>\n",
              "      <th>has_flight</th>\n",
              "      <th>has_accelerated_healing</th>\n",
              "      <th>has_weapons_master</th>\n",
              "      <th>has_intelligence</th>\n",
              "      <th>has_reflexes</th>\n",
              "      <th>has_super_speed</th>\n",
              "      <th>has_durability</th>\n",
              "      <th>has_stamina</th>\n",
              "      <th>has_agility</th>\n",
              "      <th>has_super_strength</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>3-D Man</td>\n",
              "      <td>Delroy Garrett, Jr.</td>\n",
              "      <td>Delroy Garrett, Jr.</td>\n",
              "      <td>6</td>\n",
              "      <td>Delroy Garrett, Jr. grew up to become a track ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>85</td>\n",
              "      <td>30</td>\n",
              "      <td>60</td>\n",
              "      <td>60</td>\n",
              "      <td>40</td>\n",
              "      <td>70</td>\n",
              "      <td>['Super Speed', 'Super Strength']</td>\n",
              "      <td>[]</td>\n",
              "      <td>['']</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Marvel Comics</td>\n",
              "      <td>Good</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>['Annihilators', 'Asgardians', 'Avengers', 'Ne...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Male</td>\n",
              "      <td>Human</td>\n",
              "      <td>-</td>\n",
              "      <td>-</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>/pictures2/portraits/11/050/10038.jpg?v=156096...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>A-Bomb</td>\n",
              "      <td>Richard Milhouse Jones</td>\n",
              "      <td>Richard Milhouse Jones</td>\n",
              "      <td>20</td>\n",
              "      <td>Richard \"Rick\" Jones was orphaned at a young ...</td>\n",
              "      <td>On rare occasions, and through unusual circu...</td>\n",
              "      <td>80</td>\n",
              "      <td>100</td>\n",
              "      <td>80</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>80</td>\n",
              "      <td>['Accelerated Healing', 'Agility', 'Berserk Mo...</td>\n",
              "      <td>[]</td>\n",
              "      <td>['Rick Jones']</td>\n",
              "      <td>Scarsdale, Arizona</td>\n",
              "      <td>Hulk Vol 2 #2 (April, 2008) (as A-Bomb)</td>\n",
              "      <td>Marvel Comics</td>\n",
              "      <td>Good</td>\n",
              "      <td>Musician, adventurer, author; formerly talk sh...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>['Teen Brigade', 'Ultimate Fantastic Four', 'U...</td>\n",
              "      <td>Marlo Chandler-Jones (wife); Polly (aunt); Mrs...</td>\n",
              "      <td>Male</td>\n",
              "      <td>Human</td>\n",
              "      <td>6'8 • 203 cm</td>\n",
              "      <td>980 lb • 441 kg</td>\n",
              "      <td>Yellow</td>\n",
              "      <td>No Hair</td>\n",
              "      <td>NaN</td>\n",
              "      <td>/pictures2/portraits/10/050/10060.jpg?v=158233...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>Aa</td>\n",
              "      <td>Aa</td>\n",
              "      <td>NaN</td>\n",
              "      <td>12</td>\n",
              "      <td>Aa is one of the more passive members of the P...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>80</td>\n",
              "      <td>50</td>\n",
              "      <td>55</td>\n",
              "      <td>45</td>\n",
              "      <td>100</td>\n",
              "      <td>55</td>\n",
              "      <td>['Energy Absorption', 'Energy Armor', 'Energy ...</td>\n",
              "      <td>[]</td>\n",
              "      <td>['']</td>\n",
              "      <td>Stoneworld</td>\n",
              "      <td>Green Lantern Vol 3 #21</td>\n",
              "      <td>DC Comics</td>\n",
              "      <td>Good</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>['Blue Lantern Corps', 'Green Lantern Corps', ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Male</td>\n",
              "      <td>Human</td>\n",
              "      <td>-</td>\n",
              "      <td>-</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>/pictures2/portraits/10/050/1410.jpg?v=1581168103</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>Aaron Cash</td>\n",
              "      <td>Aaron Cash</td>\n",
              "      <td>Aaron Cash</td>\n",
              "      <td>5</td>\n",
              "      <td>Aaron Cash is the head of security at Arkham A...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>80</td>\n",
              "      <td>10</td>\n",
              "      <td>25</td>\n",
              "      <td>40</td>\n",
              "      <td>30</td>\n",
              "      <td>50</td>\n",
              "      <td>['Weapon-based Powers', 'Weapons Master']</td>\n",
              "      <td>[]</td>\n",
              "      <td>['']</td>\n",
              "      <td>Gotham City</td>\n",
              "      <td>NaN</td>\n",
              "      <td>DC Comics</td>\n",
              "      <td>Good</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Male</td>\n",
              "      <td>Human</td>\n",
              "      <td>-</td>\n",
              "      <td>-</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>/pictures2/portraits/11/050/11650.jpg?v=156173...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>Aayla Secura</td>\n",
              "      <td>Aayla Secura</td>\n",
              "      <td>NaN</td>\n",
              "      <td>8</td>\n",
              "      <td>ayla Secura was a Rutian Twi'lek Jedi Knight (...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>90</td>\n",
              "      <td>40</td>\n",
              "      <td>45</td>\n",
              "      <td>55</td>\n",
              "      <td>55</td>\n",
              "      <td>85</td>\n",
              "      <td>['Accelerated Healing', 'Agility', 'Astral Pro...</td>\n",
              "      <td>[]</td>\n",
              "      <td>['']</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>George Lucas</td>\n",
              "      <td>Good</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>['Jedi Order']</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Female</td>\n",
              "      <td>Twi'lek</td>\n",
              "      <td>-</td>\n",
              "      <td>-</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>/pictures2/portraits/11/050/10891.jpg?v=156181...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 82 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0          name  ... has_agility has_super_strength\n",
              "0           0       3-D Man  ...         0.0                1.0\n",
              "1           2        A-Bomb  ...         1.0                1.0\n",
              "2           3            Aa  ...         0.0                0.0\n",
              "3           4    Aaron Cash  ...         0.0                0.0\n",
              "4           5  Aayla Secura  ...         1.0                0.0\n",
              "\n",
              "[5 rows x 82 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i4tFPrFA4_O5",
        "cell_id": "00013-00e51eac-6169-4978-9714-ee8c7a8f55b8",
        "deepnote_cell_type": "markdown"
      },
      "source": [
        "## 1.1 Obtención de Features y Bag of Words\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://media0.giphy.com/media/eIUpSyzwGp0YhAMTKr/200.gif\" width=\"300\">\n",
        "</p>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f_4NF0_V5XZ-",
        "cell_id": "00014-528c8f39-a27a-40e0-8de0-0cc7f362b4ae",
        "deepnote_cell_type": "markdown"
      },
      "source": [
        "Primero que todo, deben obtener un vector de características del atributo `history_text`, utilizando `bag of words`. En este atributo se presenta una breve descripción de la historia de cada uno de los personajes de ficción presentes en el dataset. \n",
        "\n",
        "Pero... antes de empezar, ¿Que es `bag of words`?...\n",
        "\n",
        "`bag of words` es un modelo de conteo utilizado en Procesamiento de Lenguaje Natural (NLP) que tiene como objetivo generar una representación vectorial (vector de características en nuestro cas) para cada documento a través del conteo de las palabras que contienen. \n",
        "\n",
        "La siguiente figura muestra un ejemplo de `bag of words` en acción:\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://user.oc-static.com/upload/2020/10/23/16034397439042_surfin%20bird%20bow.png\" width=\"500\">\n",
        "</p>\n",
        "\n",
        "Como pueden ver, el modelo de `bag of words` no resulta tan complicado, ¿pero cómo lo aplicamos en python?. \n",
        "\n",
        "Como podrán darse cuenta del ejemplo anterior, para facilitar el conteo será necesario transformar cada uno de los documentos en vectores, donde cada una de las posiciones posee un carácter. Este proceso es conocido como **tokenización** y lo podemos realizar de la siguiente forma:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "deepnote_to_be_reexecuted": false,
        "source_hash": "57e4888a",
        "execution_start": 1637346921830,
        "execution_millis": 8,
        "deepnote_output_heights": [
          40.399993896484375
        ],
        "cell_id": "00015-5924cc55-1587-4776-8c5e-cb400ddacaa3",
        "deepnote_cell_type": "code",
        "id": "1B00YNNb08lj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "243b19e6-1bf5-4060-88db-73ff1c156e09"
      },
      "source": [
        "docs = ['The teacher rocks like a good rock & roll',\n",
        "             'the rock is the best actor in the world']\n",
        "\n",
        "\n",
        "docs_tokenizados = [word_tokenize(doc)  for doc in docs]\n",
        "docs_tokenizados"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['The', 'teacher', 'rocks', 'like', 'a', 'good', 'rock', '&', 'roll'],\n",
              " ['the', 'rock', 'is', 'the', 'best', 'actor', 'in', 'the', 'world']]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "cell_id": "00016-649b0384-cac3-4b79-93ff-75aac3b8c5df",
        "deepnote_cell_type": "markdown",
        "id": "zzE5_UVh08lj"
      },
      "source": [
        "Podemos mejorar un poco más el proceso de tokenización agregando \n",
        "\n",
        "- Stemming:  Definimos Stemming como un algoritmo basado en reglas que transforma las palabras a una forma general. Un ejemplo de stemming, es el siguiente:\n",
        "- Eliminación de Stopwords: Eliminación de palabras muy frecuentes que entorpecen la clasificación (por ejemplo, el, la los, la, etc...)\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://devopedia.org/images/article/218/8583.1569386710.png\" width=\"300\">\n",
        "</p>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "deepnote_to_be_reexecuted": false,
        "source_hash": "d7f59237",
        "execution_start": 1637346924545,
        "execution_millis": 36,
        "deepnote_output_heights": [
          null,
          59.600006103515625
        ],
        "cell_id": "00017-52acaa25-55d2-49ee-a6c8-49437b8d4523",
        "deepnote_cell_type": "code",
        "id": "ruQsEsq_08lk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0b31bfb-e98c-466f-f32b-2c767f8f18b5"
      },
      "source": [
        "# Definimos algunas stopword que queremos que sean eliminadas\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "stop_words = stopwords.words('english')\n",
        "\n",
        "# Definimos un tokenizador con Stemming\n",
        "class StemmerTokenizer:\n",
        "    def __init__(self):\n",
        "        self.ps = PorterStemmer()\n",
        "    def __call__(self, doc):\n",
        "        doc_tok = word_tokenize(doc)\n",
        "        doc_tok = [t for t in doc_tok if t not in stop_words]\n",
        "        return [self.ps.stem(t) for t in doc_tok]\n",
        "\n",
        "# Inicializamos tokenizador\n",
        "tokenizador = StemmerTokenizer()\n",
        "\n",
        "# Creamos algunos documentos\n",
        "docs = ['The teacher rocks like a good rock & roll',\n",
        "        'the rock is the best actor in the world',\n",
        "        'New York is a beautiful city']\n",
        "\n",
        "# Obtenemos el token del primer documento\n",
        "[tokenizador(doc) for doc in docs]"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['the', 'teacher', 'rock', 'like', 'good', 'rock', '&', 'roll'],\n",
              " ['rock', 'best', 'actor', 'world'],\n",
              " ['new', 'york', 'beauti', 'citi']]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uzbzMaLOFH20",
        "outputId": "46a31a33-adea-4dea-a930-f11fba22463e"
      },
      "source": [
        "# Definimos algunas stopword que queremos que sean eliminadas\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "stop_words = stopwords.words('english')\n",
        "\n",
        "# Definimos un tokenizador con Stemming\n",
        "class StemmerTokenizer:\n",
        "    def __init__(self):\n",
        "        self.ps = PorterStemmer()\n",
        "    def __call__(self, doc):\n",
        "        doc_tok = word_tokenize(doc)\n",
        "        doc_tok = [t for t in doc_tok if t not in stop_words]\n",
        "        return [self.ps.stem(t) for t in doc_tok]\n",
        "\n",
        "# Inicializamos tokenizador\n",
        "tokenizador = StemmerTokenizer()\n",
        "\n",
        "# Creamos algunos documentos\n",
        "docs = ['The teacher rocks like a good rock & roll',\n",
        "        'the rock is the best actor in the world',\n",
        "        'New York is a beautiful city']\n",
        "\n",
        "# Obtenemos el token del primer documento\n",
        "[tokenizador(doc) for doc in docs]"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['the', 'teacher', 'rock', 'like', 'good', 'rock', '&', 'roll'],\n",
              " ['rock', 'best', 'actor', 'world'],\n",
              " ['new', 'york', 'beauti', 'citi']]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "deepnote_to_be_reexecuted": false,
        "source_hash": "2503a9b4",
        "execution_start": 1637346927213,
        "execution_millis": 13,
        "deepnote_output_heights": [
          59.600006103515625
        ],
        "cell_id": "00018-03a0f079-19df-42cb-b3b9-863a9e2ecb7a",
        "deepnote_cell_type": "code",
        "id": "1AdT5-z908ll",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5d4e232-13d4-4155-b715-819cb85c547f"
      },
      "source": [
        "# Comparación con el caso anterior\n",
        "docs_tokenizados = [word_tokenize(doc) for doc in docs]\n",
        "docs_tokenizados"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['The', 'teacher', 'rocks', 'like', 'a', 'good', 'rock', '&', 'roll'],\n",
              " ['the', 'rock', 'is', 'the', 'best', 'actor', 'in', 'the', 'world'],\n",
              " ['New', 'York', 'is', 'a', 'beautiful', 'city']]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "cell_id": "00019-3f862033-7b4e-4623-b17f-545b988af69b",
        "deepnote_cell_type": "markdown",
        "id": "Rlmw5eAU08lm"
      },
      "source": [
        "#### Al Estilo Scikit\n",
        "\n",
        "Scikit implementa `bag of words` a través de la clase `CountVectorizer()` la cual contiene muchas opciones para mejorar la tokenización."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "deepnote_to_be_reexecuted": false,
        "source_hash": "2bc7124d",
        "execution_start": 1637346927803,
        "execution_millis": 152,
        "deepnote_output_heights": [
          98,
          40.390625
        ],
        "cell_id": "00020-721a6ba0-0990-4436-9de5-4b4b53c5ff79",
        "deepnote_cell_type": "code",
        "id": "LFnJp07W08lm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "outputId": "9f551c2a-13f6-4f11-9789-15d349bf2b6f"
      },
      "source": [
        "bow = CountVectorizer(tokenizer= StemmerTokenizer())\n",
        "df = bow.fit_transform(docs)\n",
        "\n",
        "pd.DataFrame(df.toarray(), columns=bow.get_feature_names_out())"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>&amp;</th>\n",
              "      <th>actor</th>\n",
              "      <th>beauti</th>\n",
              "      <th>best</th>\n",
              "      <th>citi</th>\n",
              "      <th>good</th>\n",
              "      <th>like</th>\n",
              "      <th>new</th>\n",
              "      <th>rock</th>\n",
              "      <th>roll</th>\n",
              "      <th>teacher</th>\n",
              "      <th>world</th>\n",
              "      <th>york</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   &  actor  beauti  best  citi  good  ...  new  rock  roll  teacher  world  york\n",
              "0  1      0       0     0     0     1  ...    0     2     1        1      0     0\n",
              "1  0      1       0     1     0     0  ...    0     1     0        0      1     0\n",
              "2  0      0       1     0     1     0  ...    1     0     0        0      0     1\n",
              "\n",
              "[3 rows x 13 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "cell_id": "00021-b3e721d0-6b1f-4f91-aef8-7b04028286fe",
        "deepnote_cell_type": "markdown",
        "id": "XCP9cImM08ln"
      },
      "source": [
        "Una de las cosas más interesantes que provee son el use de n-gramas, los cuales, en palabras simples, son conjuntos de n-palabras que se concatenan entre si y que se consideran como tokens separados. \n",
        "\n",
        "Pensemos en `Nueva York`. Cuando se tokeniza Nueva York, se generan dos tokens independientes que a simple vista no tienen relación: `Nueva` `York`.\n",
        "Al usar n-gramas (en un rango min=1,max=2) , generamos tanto `Nueva` y `York` como también `Nueva York` como un token independiente."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "deepnote_to_be_reexecuted": false,
        "source_hash": "6af25c7e",
        "execution_start": 1637346930092,
        "execution_millis": 241,
        "cell_id": "00022-a7abf0fb-cbf2-4745-a96a-dcad9d4bc00f",
        "deepnote_cell_type": "code",
        "id": "3drWodHv08lo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "outputId": "ad5f99d7-2c2d-41d3-bda0-b73e9eb7a111"
      },
      "source": [
        "bow = CountVectorizer(tokenizer= StemmerTokenizer(), ngram_range=(1,2))\n",
        "df = bow.fit_transform(docs)\n",
        "\n",
        "pd.DataFrame(df.toarray(), columns=bow.get_feature_names_out())"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>&amp;</th>\n",
              "      <th>&amp; roll</th>\n",
              "      <th>actor</th>\n",
              "      <th>actor world</th>\n",
              "      <th>beauti</th>\n",
              "      <th>beauti citi</th>\n",
              "      <th>best</th>\n",
              "      <th>best actor</th>\n",
              "      <th>citi</th>\n",
              "      <th>good</th>\n",
              "      <th>good rock</th>\n",
              "      <th>like</th>\n",
              "      <th>like good</th>\n",
              "      <th>new</th>\n",
              "      <th>new york</th>\n",
              "      <th>rock</th>\n",
              "      <th>rock &amp;</th>\n",
              "      <th>rock best</th>\n",
              "      <th>rock like</th>\n",
              "      <th>roll</th>\n",
              "      <th>teacher</th>\n",
              "      <th>teacher rock</th>\n",
              "      <th>world</th>\n",
              "      <th>york</th>\n",
              "      <th>york beauti</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   &  & roll  actor  actor world  ...  teacher rock  world  york  york beauti\n",
              "0  1       1      0            0  ...             1      0     0            0\n",
              "1  0       0      1            1  ...             0      1     0            0\n",
              "2  0       0      0            0  ...             0      0     1            1\n",
              "\n",
              "[3 rows x 25 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "cell_id": "00023-55bca23d-f3d4-4f39-ae9d-e8810b522c79",
        "deepnote_cell_type": "markdown",
        "id": "iFojhP1C08lo"
      },
      "source": [
        "De los resultados, podemos ver que generamos vectores de conteo para cada una de las palabras que conforman el corpus.  Un punto extra que se agrega en esta obtención de frecuencias son los bigramas, que básicamente son el conjunto de palabras de tamaño de aparecen juntas en el texto."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "cell_id": "00024-231f49a8-163f-457d-b933-9e5dad0e1e29",
        "deepnote_cell_type": "markdown",
        "id": "qfNESCFU08lp"
      },
      "source": [
        "## Codificando los Super{heroes, villanos}  [0.5 Puntos]\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://c.tenor.com/LkQzw7k5DV4AAAAd/anime-hacking.gif\" width=\"300\">\n",
        "</p>\n",
        "\n",
        "Conociendo ahora que es el proceso de `bag of words`, aplique este modelo de obtención de caracteristicas de la siguiente forma en un pipeline:\n",
        "\n",
        "- Utilice el tokenizador entregado.\n",
        "- Obtenga caracteristicas de los unigramas y bigramas del texto (tal como el ejemplo).\n",
        "\n",
        "```python\n",
        "bog = CountVectorizer(tokenizer= StemmerTokenizer(),\n",
        "                      ngram_range=(1,2) # Este punto es opcional y es para generar bigramas\n",
        "                      )\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "cell_id": "00025-145bb273-d73c-4ad1-8b84-46327add3a2e",
        "deepnote_cell_type": "markdown",
        "id": "DSSNQWd008lp"
      },
      "source": [
        "Finalmente, aplique `MinMaxScaler()` sobre `atributos_de_interes` y concatene el valor obtenido con el matriz de caracteristicas obtenidas con bag of words.\n",
        "\n",
        "```python\n",
        "atributos_de_interes = ['intelligence_score', 'strength_score', 'speed_score', 'durability_score', 'power_score', 'combat_score']\n",
        "```\n",
        "\n",
        "No es necesario que obtenga un dataframe en concreto con las características solicitadas. Se le recomienda generar un `ColumnTransformer()` para aplicar las transformaciones solicitadas en un pipeline.\n",
        "\n",
        "**To-Do:**\n",
        "- [x] Obtener a traves de bag of words caracteristicas del resumen de historia de cada personaje.\n",
        "- [x] Aplicar MinMaxScaler sobre los atributos de interes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "cell_id": "00026-b13521a0-adf9-4c19-893e-ba6ed644ca12",
        "deepnote_cell_type": "markdown",
        "id": "cVd9m5v808lq"
      },
      "source": [
        "**Respuesta:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iCwyYi0NcpFS"
      },
      "source": [
        "bog = CountVectorizer(tokenizer= StemmerTokenizer(),\n",
        "                      ngram_range=(1,2) # Este punto es opcional y es para generar bigramas\n",
        "                      )\n",
        "\n",
        "numeric_features = ['intelligence_score', 'strength_score', 'speed_score', 'durability_score', 'power_score', 'combat_score']\n",
        "numeric_transformer = MinMaxScaler()\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers = [\n",
        "                    ('Texto', bog, 'history_text'),\n",
        "                    ('Numeric', numeric_transformer, numeric_features),\n",
        "    ])"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "stHncQ-A-j4I",
        "cell_id": "00029-0baf6cdb-9550-4717-87db-9f9900d5b276",
        "deepnote_cell_type": "markdown"
      },
      "source": [
        "## 1.2 Diseño de Baseline y  Primer Entrenamiento  [1 Puntos]\n",
        "\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://pa1.narvii.com/6374/9eaec1b7bf9157334151452a669516f9a78b954c_hq.gif\" width=\"300\">\n",
        "</p>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NeMiptpQ_EWb",
        "cell_id": "00030-1452da19-1559-4b8b-8b73-a134157c0656",
        "deepnote_cell_type": "markdown"
      },
      "source": [
        "Genere un Pipeline con las caracteristicas solicitadas en la sección 1.1, un selector de mejores features `SelectPercentile` con métrica `f_classif` y percentile=90 y un clasificador `MultinomialNB()` por defecto.\n",
        "\n",
        "Luego, separe el conjunto de datos en un conjunto de entrenamiento y prueba, donde las etiquetas estará dado por el atributo `alignment`. \n",
        "\n",
        "Finalmente entrene el modelo y reporte el desempeño con un `classification_report`. ¿ Nos recomendaría predecir la alineación de BatCow con este clasificador?.\n",
        "\n",
        "**To-DO:**\n",
        "- [x] Realizar un pipeline con las caracteristicas solicitadas en 1.1 y aplicar un clasificador  `MultinomialNB()`.\n",
        "- [x] Entrenar el pipeline y comentar los resultados."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "cell_id": "00029-34f1be30-f2df-45ac-aa14-8e05dc678be9",
        "deepnote_cell_type": "markdown",
        "id": "KgWBgMHy08ls"
      },
      "source": [
        "**Respuesta:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_hHpPDooPafy",
        "cell_id": "00031-92f07569-b6ee-48af-be9e-70cd05cb9e5e",
        "deepnote_cell_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35804eed-bf26-42f4-f25c-62d0bfb31e99"
      },
      "source": [
        "#Primero se separan los datos en train y test\n",
        "features = df_comics.loc[:, ['history_text','intelligence_score', 'strength_score', 'speed_score', 'durability_score', 'power_score', 'combat_score']]\n",
        "labels = df_comics.loc[:, \"alignment\"]\n",
        "\n",
        "#Analizar balance/desbalance de las clases\n",
        "print(\"Número de registros por clase:\\n\", labels.value_counts(),'\\n')\n",
        "\n",
        "#División en train y test\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    features, labels, test_size=0.25, shuffle=True, stratify=labels, random_state=0\n",
        ")\n",
        "\n",
        "#Creamos pipeline\n",
        "pipe = Pipeline(steps=[\n",
        "                           ('Procesador', preprocessor),\n",
        "                           (\"Selection\", SelectPercentile(f_classif, percentile=70)),\n",
        "                           ('Clasificador', MultinomialNB())\n",
        "])\n",
        "\n",
        "#Ajustamos pipeline\n",
        "pipe.fit(X_train, y_train)\n",
        "\n",
        "#Predicción\n",
        "y_pred = pipe.predict(X_test)\n",
        "\n",
        "#Resultados\n",
        "print(\"Matriz de confusión\\n\", confusion_matrix(y_pred, y_test),'\\n')\n",
        "print(\"Reporte de clasificación\\n\", classification_report(y_test, y_pred))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Número de registros por clase:\n",
            " Good       743\n",
            "Bad        429\n",
            "Neutral    113\n",
            "Name: alignment, dtype: int64 \n",
            "\n",
            "Matriz de confusión\n",
            " [[ 12   3   1]\n",
            " [ 96 183  26]\n",
            " [  0   0   1]] \n",
            "\n",
            "Reporte de clasificación\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         Bad       0.75      0.11      0.19       108\n",
            "        Good       0.60      0.98      0.75       186\n",
            "     Neutral       1.00      0.04      0.07        28\n",
            "\n",
            "    accuracy                           0.61       322\n",
            "   macro avg       0.78      0.38      0.34       322\n",
            "weighted avg       0.69      0.61      0.50       322\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dP6BbnGH2zTK"
      },
      "source": [
        "Se observa que hay un fuerte desbalance entre las clases, siendo \"Good\" la clase más frecuente y \"Neutral\" la clase con menor presencia en el dataset. Lo anterior genera que el modelo tienda a sobre estimar el número de etiquetas \"Good\" predichas. En consecuencia, analizar el accuracy del modelo nos induce un sesgo, y por tanto convendría analizar otra métrica. Teniendo eso en mente notamos que:\n",
        "\n",
        "- Para la clase \"Bad\" y \"Neutral\": Tenemos un alto precision y un bajo recall, lo cual indica que el modelo no detecta la clase muy bien, pero cuando lo hace es altamente confiable.\n",
        "\n",
        "- Para la clase \"Good\": Tenemos un alto recall y un precision menor, lo que significa que el modelo detecta bien la clase pero también incluye muestras de otras clases."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pfm7I2B7_rfB",
        "cell_id": "00035-35040b90-b6b9-4e43-8eff-15b7fa897575",
        "deepnote_cell_type": "markdown"
      },
      "source": [
        "## 1.3 Busqueda del Mejor Modelo con Grid Search [4 Puntos]\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://media1.tenor.com/images/70fdfeea52a8e2e4505498c230a0d2f9/tenor.gif?itemid=5134219\" width=\"250\">\n",
        "</p>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "14siiavzK67p",
        "cell_id": "00036-c58166cc-71f7-4fa3-94c8-c67d1145ccf1",
        "deepnote_cell_type": "markdown"
      },
      "source": [
        "No conformes con el rendimiento obtenido en la sección 1.2, el cuerpo docente les pide que realicen un **`HalvingGridSearchCV`** con diferentes parámetros para mejorar el rendimiento de la clasificación. Para esto, se le solicita que defina:\n",
        "\n",
        "- Dos clasificadores distintos en donde varie sus parámetros. Se le recomienda utilizar `LogisticRegression()` y `RandomForestClassifier()`.\n",
        "- Modificar `n-gram` range del `CountVectorizer` probando `(1,1), (1,2) y (1,3)`. \n",
        "- Selección de las mejores columnas para la clasificación con `SelectPercentile` en los percentiles `[20, 40, 60, 80]` (puede usar la métrica que usted quiera).\n",
        "\n",
        "A continuación, un ejemplo de parametros para GridSearch para una búsqueda de 3 clasificadores distintos:\n",
        "\n",
        "```python\n",
        "params = [\n",
        "       # clasificador 1 + hiperparámetros\n",
        "       {'clf': classificator1(),\n",
        "        'clf__penalty': ['ovr'],\n",
        "        'clf__multi_class': ['liblinear']},\n",
        "       # clasificador 1 + hiperparámetros    \n",
        "       {'clf': classificator2(),\n",
        "        'clf__n_estimators': [200]},\n",
        "       # clasificador 1 + hiperparámetros\n",
        "       {'clf': classificator3(),\n",
        "        ...\n",
        "       }\n",
        "       ]\n",
        "```\n",
        "\n",
        "**Nota 1**: Puede ver los parámetros modificables aplicando el método get_params() sobre su pipeline.\n",
        "\n",
        "**Nota 2**: Recuerde inicializar los clasificadores con un random state definido.\n",
        "\n",
        "**Nota 3**: Puede usar en `HalvingGridSearchCV` el parámetro `verbose=10` para ver que GridSearch le indique el estado de su ejecución.\n",
        "\n",
        "**Nota 3:** El GridSearch puede tomar tiempos de búsqueda exorbitantes, por lo que se le recomienda no agrandar mucho el espacio de búsqueda, dejar corriendo el código y tomarse un tecito."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "cell_id": "00032-3fea06e0-a390-4ae0-8036-f5fedb6d6baf",
        "deepnote_cell_type": "markdown",
        "id": "k-Yq8G6-08lu"
      },
      "source": [
        "**Respuesta:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oNvHOHELUoIv",
        "cell_id": "00037-8b06a200-cb7a-485a-b11b-31a3d0ee57f3",
        "deepnote_cell_type": "code"
      },
      "source": [
        "mb_pipe = Pipeline(steps=[\n",
        "                           ('Procesador', preprocessor),\n",
        "                           (\"Selection\", SelectPercentile(f_classif, percentile=70)),\n",
        "                           ('Clasificador', MultinomialNB(alpha = 1, fit_prior= True))\n",
        "])\n",
        "\n",
        "random_pipe = Pipeline(steps=[\n",
        "                           ('Procesador', preprocessor),\n",
        "                           (\"Selection\", SelectPercentile(f_classif, percentile=70)),\n",
        "                           ('Clasificador', RandomForestClassifier(n_estimators = 100, criterion = 'gini'))\n",
        "])\n",
        "\n",
        "logit_pipe = Pipeline(steps=[\n",
        "                           ('Procesador', preprocessor),\n",
        "                           (\"Selection\", SelectPercentile(f_classif, percentile=70)),\n",
        "                           ('Clasificador', LogisticRegression(C = 1, solver = 'lbfgs'))\n",
        "])\n",
        "\n",
        "mb_param_grid = [{\n",
        "    'Procesador__Texto__ngram_range' : [(1,1),(1,2),(1,3)],\n",
        "    'Selection__percentile' : [20,40,60,80],\n",
        "    'Clasificador__alpha' : [0.5, 1],\n",
        "    'Clasificador__fit_prior' : [True, False]\n",
        "}]\n",
        "\n",
        "random_param_grid = [{\n",
        "    'Procesador__Texto__ngram_range' : [(1,1),(1,2),(1,3)],\n",
        "    'Selection__percentile' : [20,40,60,80],\n",
        "    'Clasificador__n_estimators' : [80,100,120],\n",
        "    'Clasificador__criterion' : ['gini','entropy']\n",
        "}]\n",
        "\n",
        "logit_param_grid = [{\n",
        "    'Procesador__Texto__ngram_range' : [(1,1),(1,2),(1,3)],\n",
        "    'Selection__percentile' : [20,40,60,80],\n",
        "    'Clasificador__C' : [0.5, 1, 2],\n",
        "    'Clasificador__solver' : ['lbfgs', 'saga']\n",
        "}]"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EBbSmMPMMcZg"
      },
      "source": [
        "mb_hgs = HalvingGridSearchCV(mb_pipe, mb_param_grid, random_state = 0, n_jobs=-1).fit(X_train,y_train)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "On_-WMzxISzG"
      },
      "source": [
        "random_hgs = HalvingGridSearchCV(random_pipe, random_param_grid, random_state = 0, n_jobs = -1).fit(X_train,y_train)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v526iJWSIgN_",
        "outputId": "b92eceaf-45d5-4397-a43c-a0c55726852e"
      },
      "source": [
        "logit_hgs = HalvingGridSearchCV(logit_pipe, logit_param_grid, random_state = 0, n_jobs = -1).fit(X_train,y_train)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eA5WiN8DdIR6"
      },
      "source": [
        "y_pred_mb = mb_hgs.predict(X_test)\n",
        "y_pred_random = random_hgs.predict(X_test)\n",
        "y_pred_logit = logit_hgs.predict(X_test)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oaDrVEaRdXzE",
        "outputId": "a466dad0-c313-4609-c469-32ab7cd31f77"
      },
      "source": [
        "#Resultados\n",
        "print(\"Resultados para MB\\n\")\n",
        "print(\"Matriz de confusión\\n\", confusion_matrix(y_pred_mb, y_test),'\\n')\n",
        "print(\"Reporte de clasificación\\n\", classification_report( y_pred_mb, y_test))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Resultados para MB\n",
            "\n",
            "Matriz de confusión\n",
            " [[ 55  29  11]\n",
            " [ 49 153  15]\n",
            " [  4   4   2]] \n",
            "\n",
            "Reporte de clasificación\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         Bad       0.51      0.58      0.54        95\n",
            "        Good       0.82      0.71      0.76       217\n",
            "     Neutral       0.07      0.20      0.11        10\n",
            "\n",
            "    accuracy                           0.65       322\n",
            "   macro avg       0.47      0.49      0.47       322\n",
            "weighted avg       0.71      0.65      0.67       322\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VRAhY5Awdr7n",
        "outputId": "42ae049a-f638-431b-83f7-a17e438e501c"
      },
      "source": [
        "#Resultados\n",
        "print(\"Resultados para Random Forest\\n\")\n",
        "print(\"Matriz de confusión\\n\", confusion_matrix(y_pred_random, y_test),'\\n')\n",
        "print(\"Reporte de clasificación\\n\", classification_report( y_pred_random, y_test))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Resultados para Random Forest\n",
            "\n",
            "Matriz de confusión\n",
            " [[ 24   6   4]\n",
            " [ 84 180  24]\n",
            " [  0   0   0]] \n",
            "\n",
            "Reporte de clasificación\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         Bad       0.22      0.71      0.34        34\n",
            "        Good       0.97      0.62      0.76       288\n",
            "     Neutral       0.00      0.00      0.00         0\n",
            "\n",
            "    accuracy                           0.63       322\n",
            "   macro avg       0.40      0.44      0.37       322\n",
            "weighted avg       0.89      0.63      0.71       322\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_muG-z3cdt3f",
        "outputId": "317ed6ba-929f-4a2a-81a7-d25f62927ee7"
      },
      "source": [
        "#Resultados\n",
        "print(\"Resultados para logit\\n\")\n",
        "print(\"Matriz de confusión\\n\", confusion_matrix(y_pred_logit, y_test),'\\n')\n",
        "print(\"Reporte de clasificación\\n\", classification_report( y_pred_logit, y_test))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Resultados para logit\n",
            "\n",
            "Matriz de confusión\n",
            " [[ 61  24   8]\n",
            " [ 44 158  17]\n",
            " [  3   4   3]] \n",
            "\n",
            "Reporte de clasificación\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         Bad       0.56      0.66      0.61        93\n",
            "        Good       0.85      0.72      0.78       219\n",
            "     Neutral       0.11      0.30      0.16        10\n",
            "\n",
            "    accuracy                           0.69       322\n",
            "   macro avg       0.51      0.56      0.52       322\n",
            "weighted avg       0.74      0.69      0.71       322\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OmQUw2aZ_6z2",
        "cell_id": "00042-1dc5444c-59e9-4d79-93fb-3c545fe3b086",
        "deepnote_cell_type": "markdown"
      },
      "source": [
        "## 1.4 Predicción del datos sin etiquetado  [0.5 puntos]\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://pbs.twimg.com/media/DolotxUUYAAbg7f.jpg\" width=\"350\">\n",
        "</p>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cj0ERBgTBFWN",
        "cell_id": "00043-bdf593d2-92b5-4d74-869a-8c9541a6e572",
        "deepnote_cell_type": "markdown"
      },
      "source": [
        "LLego el momento de predecir \n",
        "`Vergil`, `Gorilla Girl` y `Batcow`\n",
        "\n",
        "\n",
        "**Nota:** Recuerde que pueden existir campos vacios en `history_text`, por lo que se les recomienda borrar los nan."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "cell_id": "00035-1e9b40e0-20dc-4ed1-81ca-b7f8f9679771",
        "deepnote_cell_type": "markdown",
        "id": "hHrt6Mcb08lv"
      },
      "source": [
        "**Respuesta:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00035-1ec91701-af2f-4571-9067-f82dbc6f2989",
        "deepnote_cell_type": "code",
        "id": "oVbtVXKy08lw"
      },
      "source": [
        "df_comics_no_label = df_comics_no_label.drop_duplicates(subset = ['name'])\n",
        "df_comics_no_label = df_comics_no_label.dropna(subset=['history_text']) # eliminar ejemplos sin historia\n",
        "df_comics_no_label = df_comics_no_label.reset_index(drop=True)\n",
        "df_comics_no_label = df_comics_no_label.drop(columns = ['alignment'])\n",
        "\n",
        "X = df_comics_no_label.loc[:, ['history_text','intelligence_score', 'strength_score', 'speed_score', 'durability_score', 'power_score', 'combat_score']]\n",
        "\n",
        "#Se elige logit porque entregó los mejores resultados\n",
        "pred = logit_hgs.predict(X)\n",
        "\n",
        "df_comics_no_label['alignment'] = pred"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "h6sVv5HPeyY4",
        "outputId": "341eb312-079f-4065-8b61-07c7df50f38d"
      },
      "source": [
        "lista = ['Vergil', 'Gorilla Girl' , 'Batcow']\n",
        "df_comics_no_label[df_comics_no_label.name.isin(lista)].loc[:,['name','alignment']]"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "      <th>alignment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Batcow</td>\n",
              "      <td>Good</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>Gorilla Girl</td>\n",
              "      <td>Good</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>71</th>\n",
              "      <td>Vergil</td>\n",
              "      <td>Good</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            name alignment\n",
              "14        Batcow      Good\n",
              "37  Gorilla Girl      Good\n",
              "71        Vergil      Good"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rg4ZMq8ezAH6",
        "cell_id": "00045-bf830861-7edd-434b-93f5-af4b0404ce83",
        "deepnote_cell_type": "markdown"
      },
      "source": [
        "# Conclusión\n",
        "Eso ha sido todo para el lab de hoy, recuerden que el laboratorio tiene un plazo de entrega de una semana y que **los días de atraso no se pueden utilizar para entregas de lab, solo para tareas**. Cualquier duda del laboratorio, no duden en contactarnos por mail o U-cursos.\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://media1.tenor.com/images/fb5bf7cc5a4acb91b4177672886a88ba/tenor.gif?itemid=5591338\">\n",
        "</p>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "created_in_deepnote_cell": true,
        "deepnote_cell_type": "markdown",
        "id": "oG3tCp4I08lw"
      },
      "source": [
        "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=87110296-876e-426f-b91d-aaf681223468' target=\"_blank\">\n",
        "<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\n",
        "Created in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>"
      ]
    }
  ]
}